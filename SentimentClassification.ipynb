{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentClassification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szJfZx2G-uhJ"
      },
      "source": [
        "Importing google drive file to load dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQxwZLh7i7z1",
        "outputId": "9e1d91c0-4398-49c0-adbf-82089529c04d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUk67PDr-3aD"
      },
      "source": [
        "Importing all library will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rplEc0bmjKjj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "from nltk.tokenize import word_tokenize \n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGFIZdd9_PDa"
      },
      "source": [
        "First of all, we need to load dataset into array/list. Code below are syntax to load csv file using pandas library. Each file (train and test) are assigned to different array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlGuugSRjTct"
      },
      "source": [
        "train = pd.read_csv(\"drive/My Drive/Clader Follow-Up Task/train_dataset.csv\")\n",
        "test = pd.read_csv(\"drive/My Drive/Clader Follow-Up Task/test_dataset.csv\")\n",
        "review_train = train.verified_reviews # making \"verified_reviews\" column in train data as single array\n",
        "review_test = test.verified_reviews # making \"verified_reviews\" column in test data as single array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lknk3LtJ_2BS"
      },
      "source": [
        "Here is the example of loaded train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "D9zxoauJu3Qd",
        "outputId": "1aef9cbd-d7d0-4562-9e90-bf4d373785bc"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>variation</th>\n",
              "      <th>verified_reviews</th>\n",
              "      <th>feedback</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Charcoal Fabric</td>\n",
              "      <td>Loved it!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Walnut Finish</td>\n",
              "      <td>Sometimes while playing a game, you can answer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Charcoal Fabric</td>\n",
              "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Heather Gray Fabric</td>\n",
              "      <td>I received the echo as a gift. I needed anothe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Sandstone Fabric</td>\n",
              "      <td>Without having a cellphone, I cannot use many ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2516</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>Perfect for kids, adults and everyone in betwe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2517</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>Listening to music, searching locations, check...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2518</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>I do love these things, i have them running my...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2519</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>White  Dot</td>\n",
              "      <td>Only complaint I have is that the sound qualit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2520</th>\n",
              "      <td>4</td>\n",
              "      <td>29-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2521 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      rating  ... feedback\n",
              "0          5  ...        1\n",
              "1          4  ...        1\n",
              "2          5  ...        1\n",
              "3          5  ...        1\n",
              "4          3  ...        1\n",
              "...      ...  ...      ...\n",
              "2516       5  ...        1\n",
              "2517       5  ...        1\n",
              "2518       5  ...        1\n",
              "2519       5  ...        1\n",
              "2520       4  ...        1\n",
              "\n",
              "[2521 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axfR7L5QACGK"
      },
      "source": [
        "To make a good model in Natural Language Processing system especially sentiment classification, we need to do data preprocessing first. Preprocessing steps in function below are :\n",
        "<ul> \n",
        "  <li> Removing unwanted special characters. (Such as: ,.{} etc) </li>\n",
        "  <li> Lowercasing word </li>\n",
        "  <li> Tokenizing word (Example : [\"Saya adalah mahasiswa\"], the result of tokenizing process is [\"Saya\", \"adalah\", \"mahasiswa\"] </li>\n",
        "  <li> Lemmatizing word </li>\n",
        "</ul>\n",
        "\n",
        "Lemmatizing word means to find a root/base word from corresponding word. For example, there are set of words = [\"loves\", \"loving\", \"loved\"]. The result after lemmatizing that set of words is:\n",
        "<ul> \n",
        "  <li> loves -> love </li>\n",
        "  <li> loving -> love </li>\n",
        "  <li> loved -> love </li>\n",
        "</ul>\n",
        "\n",
        "So, the purpose of lemmatizing word is <b> to reduce the variance of text data</b>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFk90dFhuWIP"
      },
      "source": [
        "def preprocessing(data):\n",
        "  wnl = WordNetLemmatizer()\n",
        "  result = []\n",
        "  for i in range(0,len(data)):\n",
        "    words = data[i]\n",
        "    words = re.sub('[~`!@#$%^&*():;\"{}_/?><\\|.,`0-9]', '', words)\n",
        "    words = str.lower(words)\n",
        "    words = word_tokenize(words)\n",
        "    words = ([wnl.lemmatize(words[i],\"v\") for i in range(0,len(words))])\n",
        "    result.append(words)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK9rhQANxtdJ"
      },
      "source": [
        "review_train = preprocessing(review_train)\n",
        "review_test = preprocessing(review_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coxwITYyC6Yw"
      },
      "source": [
        "Below is an example of preprocessing data on the first record of train data. The first line is text input, and the second line is the preprocess result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT5rM3OG0zYk",
        "outputId": "ffa220b7-14ae-4287-8fad-ce649640ac2c"
      },
      "source": [
        "print(train.verified_reviews[0])\n",
        "print(review_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loved it!\n",
            "['love', 'it']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHXXGJLODXBB"
      },
      "source": [
        "Because we will be using a Doc2Vec( ) approach, the input data must be in document type. Therefore, code below is a process to convert array into document-type object. Inside of document, there are 2 components, first is \"words\" that contain preprocessed text, and the second is \"tags\" that contain a label of every records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f4pLovgzPVt"
      },
      "source": [
        "dTrain = []\n",
        "analyzedDocument1 = namedtuple('AnalyzedDocument1', 'words tags')\n",
        "for i in range(len(train)):\n",
        "    words = review_train[i]\n",
        "    tags = [train.feedback[i]]\n",
        "    dTrain.append(analyzedDocument1(words, tags))\n",
        "dTrain = pd.Series(dTrain)\n",
        "\n",
        "dTest = []\n",
        "analyzedDocument2 = namedtuple('AnalyzedDocument2', 'words tags')\n",
        "for i in range(len(test)):\n",
        "    words = review_test[i]\n",
        "    tags = [test.feedback[i]]\n",
        "    dTest.append(analyzedDocument2(words, tags))\n",
        "dTest = pd.Series(dTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IscdtOxQEXPi"
      },
      "source": [
        "After we conduct a perfect preprocessing step, the next thing we have to do is building a vocabulary using Doc2Vec( ) approach. Basically, Doc2Vec( ) doing a training process on train data and produce a vocabulary that can be used for predicting test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEMY9_Nw0lQx"
      },
      "source": [
        "max_epochs = 20 # number of iterations/learning\n",
        "vec_size = 5 # vector dimension\n",
        "alpha = 0.025 # learning rate\n",
        "model = Doc2Vec(vector_size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.0025,\n",
        "                min_count=5,\n",
        "                dm =1)\n",
        "  \n",
        "model.build_vocab(dTrain) # training to produce/achieve vocabulary."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNgjghC-0tky",
        "outputId": "83bfb495-4252-4d4b-f85a-97faf7f17485"
      },
      "source": [
        "for epoch in range(max_epochs):\n",
        "    print('Iteration : {0}'.format(epoch+1))\n",
        "    model.train(dTrain,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.epochs)\n",
        "\n",
        "    model.alpha -= 0.0002 # each iteration will be reduced of 0.0002 learning rate.\n",
        "\n",
        "    model.min_alpha = model.alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration : 1\n",
            "Iteration : 2\n",
            "Iteration : 3\n",
            "Iteration : 4\n",
            "Iteration : 5\n",
            "Iteration : 6\n",
            "Iteration : 7\n",
            "Iteration : 8\n",
            "Iteration : 9\n",
            "Iteration : 10\n",
            "Iteration : 11\n",
            "Iteration : 12\n",
            "Iteration : 13\n",
            "Iteration : 14\n",
            "Iteration : 15\n",
            "Iteration : 16\n",
            "Iteration : 17\n",
            "Iteration : 18\n",
            "Iteration : 19\n",
            "Iteration : 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHcLGC5uFffN"
      },
      "source": [
        "The function below (vec_for_learning) is a function to generate the vector of each record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq4Lb29V18lh"
      },
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=5)) for doc in sents])\n",
        "    return regressors,targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpEfwV0z2XAT"
      },
      "source": [
        "X_train,y_train = vec_for_learning(model, dTrain)\n",
        "X_test,y_test = vec_for_learning(model, dTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQe1DTEhFzu6"
      },
      "source": [
        "As a comparison, I'm using Random Forest and K-Nearest Neighbors (KNN) as the classifiers. It shows that Random Forest has a best training accuracy (98,73%), and KNN has a best testing accuracy (94.28%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnbFSF2N2hmm",
        "outputId": "dfafd540-5c84-4582-dde5-77ef19aaf803"
      },
      "source": [
        "RF_clf = RandomForestClassifier(n_estimators=10, random_state = 42)\n",
        "RF_clf.fit(X_train, y_train)\n",
        "pred1 = RF_clf.predict(X_train)\n",
        "print('Training accuracy (Random Forest) : %.2f%%' % (accuracy_score(pred1, y_train)*100))\n",
        "pred2 = RF_clf.predict(X_test)\n",
        "print('Testing accuracy (Random Forest) : %.2f%%' % (accuracy_score(pred2, y_test)*100))\n",
        "print(\"Confusion Matrix of Random Forest:\")\n",
        "print(confusion_matrix(y_test,pred2))\n",
        "print()\n",
        "KNN_clf = KNeighborsClassifier(n_neighbors=9)\n",
        "KNN_clf.fit(X_train, y_train)\n",
        "pred3 = KNN_clf.predict(X_train)\n",
        "print('Training accuracy (K-NN) : %.2f%%' % (accuracy_score(pred3, y_train)*100))\n",
        "pred4 = KNN_clf.predict(X_test)\n",
        "print('Testing accuracy (K-NN) : %.2f%%' % (accuracy_score(pred4, y_test)*100))\n",
        "print(\"Confusion Matrix of K-NN:\")\n",
        "print(confusion_matrix(y_test,pred4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy (Random Forest) : 98.73%\n",
            "Testing accuracy (Random Forest) : 93.00%\n",
            "Confusion Matrix of Random Forest:\n",
            "[[ 14  29]\n",
            " [ 15 571]]\n",
            "\n",
            "Training accuracy (K-NN) : 93.97%\n",
            "Testing accuracy (K-NN) : 94.28%\n",
            "Confusion Matrix of K-NN:\n",
            "[[  9  34]\n",
            " [  2 584]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBEMaLSfGVJr"
      },
      "source": [
        "To get the predictions more accurate, we shall consider the \"rating\" column in the dataset. In every record that we had predict, each label (0 and 1) has probability value (using .predict_proba() ) of the prediction. We need a <b>threshold</b> to make the \"rating\" column considered for a better prediction. How it works is as follows. <br>\n",
        "Threshold 1 (for label 1):\n",
        "\n",
        "1. 0.01\n",
        "2. 0.1\n",
        "3. 0.6\n",
        "4. 0.9\n",
        "5. 1.0\n",
        "\n",
        "Threshold 2 (for label 0):\n",
        "\n",
        "1. 1.0\n",
        "2. 0.9\n",
        "3. 0.6\n",
        "4. 0.1\n",
        "5. 0.01\n",
        "\n",
        "For example, on a record we have: <br>\n",
        "probability of 0 : 0.612 <br>\n",
        "probability of 1 : 0.388 <br>\n",
        "Prediction Result : 0 <br>\n",
        "Actual Label : 1 <br>\n",
        "Rating : 4 <br> <br>\n",
        "The new prediction will be: <br>\n",
        "P(0) = 0.612 x 0.1 = <b> 0.0612 </b> <br>\n",
        "P(1) = 0.388 x 0.9 = <b> 0.3492 </b>\n",
        "\n",
        "Because of P(1) > P(0), so the new prediction is 1 and it equals with the actual label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko_67mDj7gis"
      },
      "source": [
        "proba1 = RF_clf.predict_proba(X_test)\n",
        "proba2 = KNN_clf.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5A_JXFV7w71"
      },
      "source": [
        "def predict_using_threshold(proba):\n",
        "  thresh1 = [0.01,0.1,0.6,0.9,1.0]\n",
        "  thresh2 = np.flip(thresh1)\n",
        "  predictions = []\n",
        "  for i in range(0,len(proba)):\n",
        "    rate = test.rating[i]\n",
        "    new_prob1 = thresh1[rate-1] * proba[i][1]\n",
        "    new_prob2 = thresh2[rate-1] * proba[i][0]\n",
        "    if new_prob1>new_prob2:\n",
        "      res=1\n",
        "    else:\n",
        "      res=0\n",
        "    predictions.append(res)\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KtAPh12KW1y"
      },
      "source": [
        "Here are the final accuracy of the sentiment prediction/classification. It shows a better confusion matrix and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14SwcNPQ4dcK",
        "outputId": "7dd2f29e-df1c-4f11-bca5-fcc329c61e93"
      },
      "source": [
        "pred5 = predict_using_threshold(proba1)\n",
        "pred6 = predict_using_threshold(proba1)\n",
        "\n",
        "print('Final Test accuracy (Random Forest): %.2f%%' % (accuracy_score(pred5, y_test)*100))\n",
        "print(\"Final Confusion Matrix of Random Forest:\")\n",
        "print(confusion_matrix(y_test,pred5))\n",
        "print()\n",
        "print('Final Test accuracy (K-NN) : %.2f%%' % (accuracy_score(pred6, y_test)*100))\n",
        "print(\"Final Confusion Matrix of K-NN:\")\n",
        "print(confusion_matrix(y_test,pred6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Test accuracy (Random Forest): 97.30%\n",
            "Final Confusion Matrix of Random Forest:\n",
            "[[ 32  11]\n",
            " [  6 580]]\n",
            "\n",
            "Final Test accuracy (K-NN) : 97.30%\n",
            "Final Confusion Matrix of K-NN:\n",
            "[[ 32  11]\n",
            " [  6 580]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZI8mEVs-qk9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}